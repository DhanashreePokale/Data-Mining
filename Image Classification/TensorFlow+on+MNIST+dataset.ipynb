{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with TensorFlow\n",
    "\n",
    "## TensorFlow on MNIST dataset\n",
    "\n",
    "\n",
    "### What is TensorFlow?\n",
    "One of the articles (http://www.businessinsider.com/what-is-google-tensorflow-2015-11) from Business Insider mentioned about Google's TensorFlow as Artificial Intelligence System of Google. As this article describes, Google built a machine learning system that was fed with an image and it returned if it was a cat or a dog. Steps taken to implement this on a high level were that first the TensorFlow sorts through data layers where every step is performing certain tasks like identifying shape in the picture and then next layer gets into more detailed identification and so on. These layers can be refered to as nodes. This process of compiling information layer by layer to make final identification is called as Tensor & process is called TensorFlow.\n",
    "\n",
    "### About MNIST dataset\n",
    "The dataset is hosted on http://yann.lecun.com/exdb/mnist/ .\n",
    "It is a database of handwritten digits with training samples of 60000 examples and 10000 test examples. This is a subset data of NIST database. The digits are normalized and centered in a fixed-size image.\n",
    "\n",
    "### References\n",
    "1. https://www.youtube.com/watch?v=wuo4JdG3SvU\n",
    "2. https://www.tensorflow.org/get_started/mnist/mechanics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries essential for this analysis.\n",
    "\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# We now download MNIST dataset which is about 12MB\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"data/MNIST/\", one_hot = True)\n",
    "\n",
    "# We used one_hot= True which means we enable one hot encoding for the dataset. \n",
    "# This means that the label for each sample in the dataset is a vector of number of classes \n",
    "# (here number of classes are 10) and only 1 element of that vector would be 1 rest all would be 0.\n",
    "# If the 8th element of that vector is 1, then label is 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set:\t\t55000\n",
      "Test-set:\t\t10000\n",
      "Validation-set:\t\t5000\n"
     ]
    }
   ],
   "source": [
    "# We check the size of the datasets Train, Test and Validation\n",
    "\n",
    "print(\"Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"Validation-set:\\t\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 2, 6, 9, 7, 2, 9, 1, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We noticed that the labels are hot encoded. \n",
    "# We figure out the exact class label number using following code-\n",
    "data.train.cls = np.array([label.argmax() for label in data.train.labels])\n",
    "data.train.cls[0:10] # labels for first 10 images in training dataset\n",
    "# We figure out the exact class label number using following code-\n",
    "data.test.cls = np.array([label.argmax() for label in data.test.labels])\n",
    "data.test.cls[0:10] # labels for first 10 images in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Dimensions or setting variables for some essential known factors\n",
    "image_size = 28 # MNIST images are 28x28 pixeled\n",
    "image_size_flat = image_size*image_size # one dimensional array for image\n",
    "image_shape = (image_size, image_size) # size in this case is (28,28) indicating height and width in pixels\n",
    "number_classes = 10 # total number of labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEX4gKMIPBPX/EhqoeSQulYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118619550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We check what is the first image and reshape is used because data.train.images[1] is 1 dimensional vector \n",
    "# and we need to reshape it to be of 28x28 shaped pixel image\n",
    "plt.imshow(data.train.images[1].reshape(image_shape)) \n",
    "print(data.train.labels[1])\n",
    "print(data.train.cls[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of TensorFlow is to have a computational graph. \n",
    "#### TensorFlow graph consists of -\n",
    "1. Placeholder variables - used for changing graph inputs\n",
    "2. Model variables - used for finding optimized model parameters\n",
    "3. Model\n",
    "4. Cost Metric- used for optimizing the model variables\n",
    "5. Optimization Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Placeholder Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define the placeholder variable\n",
    "X = tf.placeholder(tf.float32,[None, image_size_flat])\n",
    "# tf.float32 is data type float for the placeholder variable\n",
    "# then this variable is a 2 D variable/array/matrix where we set number of rows for this matrix to be none,\n",
    "# which means it can have any number of rows and number of columns is fixed to image_size_flat (28*28)\n",
    "# This means X has many rows, one row per image & all the images are flattened thus having total 28*28 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every image there is corresponding label\n",
    "# we create a place holder for label\n",
    "# its datatype is float and number of rows is not fixed but number of columns is equal to total unique classes (i.e. 10)\n",
    "y_true = tf.placeholder(tf.float32, [None,number_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actual Class\n",
    "# Number of rows could be arbitrary\n",
    "# data type is integer\n",
    "# This is a 1 dimensional vector storing only class labels in integer format\n",
    "y_true_class = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Variables or Parameters to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define weights variable for optimization\n",
    "# initialize it to 0\n",
    "weights = tf.Variable(tf.zeros([image_size_flat, number_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also define bias\n",
    "# Initialize it to 0\n",
    "bias = tf.Variable(tf.zeros([number_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model is supposed to multiply weights to the columns of flattened image and then add bias\n",
    "# Result is a matrix of [number_of_images, number_classes]\n",
    "# Weight is matrix of size [image_size_flat, number_classes]\n",
    "# image is a matrix of size [number_of_images, image_size_flat]\n",
    "# bias is a matrix of size [number_of_images]\n",
    "\n",
    "# we name the model as logits as it is a typical TensorFlow terminology\n",
    "logits = tf.matmul(X,weights)+bias\n",
    "\n",
    "# The output of this model is a matrix with rows containing image and columns containing class(0 to 9)\n",
    "# Element value of ith row and jth column indicates how likely the ith image corresponds to jth class.\n",
    "\n",
    "# The output of these models however are rough estimates and interpretation is difficult so normalization is advised\n",
    "# To interpret these values as probabilities, we normalize the values such that over all classes the sum is 1\n",
    "# This can be accomplished using softmax\n",
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "# this gives the predicted class by choosing the class that has highest probability listed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose is to optimize weights and biases\n",
    "# Cross entropy is used as it gives a continuous function such that if the match is perfect output is 0 else \n",
    "# it returns some positive value\n",
    "# For every image we calculate cross entropy between true and predicted classes\n",
    "# we will use logits model and y_true for buiding this cost function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y_true)\n",
    "\n",
    "# this gives cross entropy for every input image\n",
    "# for single scaler value to be returned by the cross_entropy, average of all cross_entropy is calculated\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we shall use gradient descent method\n",
    "# minimize the cross_entropy cost\n",
    "# set step size as 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find out correct number of predictions\n",
    "correct_pred = tf.equal(y_pred_cls, y_true_class)\n",
    "\n",
    "# we find now the classification accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph\n",
    "\n",
    "### Initiate TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First create TensorFlow session\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables weights and bias before optimizing them\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimization Iterations Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a batch_size for passing only a set of images from the training data as dataset contains over 50000 images\n",
    "batch_size = 200\n",
    "\n",
    "# define the function for optimizing which takes in iterations required\n",
    "# for every iteration it should take a random batch of 100 images \n",
    "# for every iteration it should have a dictionary storing the image and its true labels\n",
    "# for every iteration then we run the optimizer function with the feed dictionary\n",
    "\n",
    "def optimize(iterations):\n",
    "    for i in range(iterations):\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "        feed_dict_training = {x: x_batch, y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict = feed_dict_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to find performance (Performance measures and functions.....) Work in progress.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
