---
title: "Ordinal Regression on Wine"
author: "Dhanashree Pokale"
date: "4/19/2017"
output:
  html_document: default
  pdf_document: default
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "README_figs/README-"
)
```
### Aim of this project is to use ordinal regression technique to predict wine quality. The dataset used is from UCI Machine Learning Repository. 

### About data:
##### The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.). 

##### These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods. 


### Attribute Information:

##### For more information, read [Cortez et al., 2009]. 
##### Input variables (based on physicochemical tests): 
  1. fixed acidity 
  2. volatile acidity 
  3. citric acid 
  4. residual sugar 
  5. chlorides 
  6. free sulfur dioxide 
  7. total sulfur dioxide 
  8. density 
  9. pH 
  10. sulphates 
  11. alcohol
  
##### Output variable
  12. quality (score between 0 and 10)



##### Required Packages
  * require(foreign)
  * require(ggplot2)
  * require(MASS)
  * require(lattice)
  * require(survival)
  * require(Formula)
  * require(Hmisc)
  * require(reshape2)
```{r include=FALSE}
# Required Packages

require(foreign)
require(ggplot2)
require(MASS)
require(lattice)
require(survival)
require(Formula)
require(Hmisc)
require(reshape2)
```

##### We start by clearing the workspace.
```{r}
# Load Data
# Clear Workspace####
ls()
rm(list = ls())
```

##### Load the data.Here, we shall proceed only with Red Wine Quality Data Analysis.
```{r}
# read data ####
red_wine <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv", sep = ";")
#white_wine <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv", sep = ";")

# Rename the columns ####
colnames(red_wine) <- c("FixedAcidity","VolatileAcidity","CitriAcid","ResidualSugar","Chlorides","FreeSO2","TotalSO2","Density","pH","Sulphates","Alcohol","Quality")
#colnames(white_wine) <- c("FixedAcidity","VolatileAcidity","CitriAcid","ResidualSugar","Chlorides","FreeSO2","TotalSO2","Density","pH","Sulphates","Alcohol","Quality")
```

##### Analysis for red wine
```{r}
# Check data values ####
head(red_wine) 
```
##### Quality is the response variable to be classified. 10 represents best, 1 represents worse. This variable has 10 levels.

##### Factorize response variable
```{r}
red_wine$Quality <- as.factor(red_wine$Quality)
red_wine$Out <- relevel(red_wine$Quality, ref="3")
```
##### Ordinal Regression For building this model, we will be using the polr command to estimate an ordered logistic regression. Then, we’ll specify Hess=TRUE to let the model output show the observed information matrix from optimization which is used to get standard errors.

##### Sampling variables
##### Set seed as M-number. Sample 75% of data as training data and rest 25% as testing data
```{r}
set.seed(5665)
subset_indices = sample(nrow(red_wine),nrow(red_wine)*0.75)
RW_train = red_wine[subset_indices,]
RW_test = red_wine[-subset_indices,]
```


##### For building this model, we will be using the polr command to estimate an ordered logistic regression. Then, we’ll specify Hess=TRUE to let the model output show the observed information matrix from optimization which is used to get standard errors.

```{r}
m <- polr(Quality
          ~ Alcohol+FixedAcidity + VolatileAcidity+CitriAcid+ResidualSugar + Chlorides+FreeSO2+TotalSO2+Density+pH +Sulphates, 
          data = RW_train, method = "probit", Hess=TRUE)
summary(m)
```

##### Predict on new cases
```{r}
head(predict(m, RW_test, type = "p"))
```

##### Check if the probabilities are statistically different for every scenario or new test case
```{r}
exp(cbind(OR=coef(m), confint(m)))
```
For this we find out which variables are statistically important.
If 0 lies in confidence interval then estimate of coeff is not significant in linear model.
Here we are using exponential of 0 which is 1. So, if 1 lies in the confidence interval then the estimate of coeff is not significant.

Here, we see that 1 lies in confidence interval for  FixedAcidity, CitricAcid, ResidualSugar. Thus, these coeffs are not significant.

Significant coeffs are - *Alcohol*, *Volatile Acidity*,*Chlorides*,*FreeSO2*, *TotalSO2*, *pH* & *Suphates*
**Hence, our model should have only *Alcohol*, *Volatile Acidity*,*Chlorides*,*FreeSO2*, *TotalSO2*, *pH* & *Suphates* Variables.**
We, drop other variables and rebuild the model.

OR values here make sense with respect to base case which we have set as 3.
* So, when Alcohol content increases by 1 unit, the odds ratio for Quality of wine increases from 3 to some other level by 1.502.
* when  Volatile Acidity increases by 1 unit, the odds ratio for Quality increases from 3 to some other level by 0.17.

##### We rebuild the model using significant variables only.
```{r}
m1 <- polr(Quality
          ~ Alcohol + VolatileAcidity + Chlorides+FreeSO2+TotalSO2+pH +Sulphates, 
          data = RW_train, method = "probit", Hess=TRUE)
summary(m1)
```

##### Predict on new cases
```{r}
head(predict(m1, RW_test, type = "p"))
```

##### head of RW_test
```{r}
RW_test[1:4,]
```


##### Misclassification or Confusion Matrix
```{r}
Probability_TestDataset_Quality <- predict(m1, RW_test, type = "p")
predictedWineScore_Test <- predict(m1, RW_test)
table(RW_test$Quality, predictedWineScore_Test)
error <- predictedWineScore_Test - RW_test$Quality
```

##### Misclassification Rate
```{r}
mean((predictedWineScore_Test) != RW_test$Quality)  # misclassification error
```

##### Modified Misclassification Rate. We apply weights to determine the accuracy. For exact prediction weight of 1 is given. For a prediction that is off by 1 rank, we give the weight of 0.6 and for 2 ranking off prediction, we give the ranking of 0.3. This accuracy measure shows that Ordinal Regression is doing a good job at making predictions close enough to the real ranks of wine quality.
```{r}
### classification Rate
x1 <- mean((predictedWineScore_Test == RW_test$Quality))
x2 <- mean(0.60*((as.numeric(predictedWineScore_Test)-1) == RW_test$Quality))
x3 <- mean(0.60*((as.numeric(predictedWineScore_Test)+1) == RW_test$Quality))
x4 <- mean(0.30*((as.numeric(predictedWineScore_Test)-2) == RW_test$Quality))
x5 <- mean(0.30*((as.numeric(predictedWineScore_Test)+2) == RW_test$Quality))
1-sum(x1,x2,x3,x4,x5) #misclassification
sum(x1,x2,x3,x4,x5)

```



